{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mexican-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os, sys, glob, pickle\n",
    "from xml.dom import minidom\n",
    "import matplotlib.path as mplPath\n",
    "import numpy as np\n",
    "import openslide\n",
    "import time\n",
    "import pdb\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "experimental-charleston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bridal-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "molecular-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '_ckpt_epoch_9.ckpt'\n",
    "RETURN_PREACTIVATION = True  # return features from the model, if false return classification logits\n",
    "NUM_CLASSES = 4  # only used if RETURN_PREACTIVATION = False\n",
    "\n",
    "\n",
    "def load_model_weights(model, weights):\n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "    weights = {k: v for k, v in weights.items() if k in model_dict}\n",
    "    if weights == {}:\n",
    "        print('No weight could be loaded..')\n",
    "    model_dict.update(weights)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = models.__dict__['resnet18'](pretrained=False)\n",
    "\n",
    "state = torch.load(MODEL_PATH, map_location=device)\n",
    "\n",
    "state_dict = state['state_dict']\n",
    "for key in list(state_dict.keys()):\n",
    "    state_dict[key.replace('model.', '').replace('resnet.', '')] = state_dict.pop(key)\n",
    "\n",
    "model = load_model_weights(model, state_dict)\n",
    "\n",
    "if RETURN_PREACTIVATION:\n",
    "    model.fc = torch.nn.Sequential()\n",
    "else:\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fifty-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward_once(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_once(x1)\n",
    "        out2 = self.forward_once(x2)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "given-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamDataset(Dataset):\n",
    "    def __init__(self, img_file_list, mode='load', affine_param=5, jitter_param=0.4):\n",
    "        self.img_file_list = img_file_list\n",
    "        \n",
    "        self.mode = mode\n",
    "        if mode=='create':\n",
    "            self.single_transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.RandomCrop(224),\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ])\n",
    "            self.augment = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "                torchvision.transforms.RandomAffine(affine_param),\n",
    "                torchvision.transforms.ColorJitter(\n",
    "                    brightness=jitter_param,\n",
    "                    contrast=jitter_param,\n",
    "                    saturation=jitter_param)\n",
    "            ])\n",
    "\n",
    "            self.wsi_list = []\n",
    "            self.wsi_weight = []\n",
    "            for img_file in img_file_list:\n",
    "                wsi = Image.open(img_file).convert('RGB')\n",
    "                self.wsi_list.append(wsi)\n",
    "                h,w = wsi.size\n",
    "                self.wsi_weight.append(h*w)\n",
    "        \n",
    "    def sample(self):\n",
    "        wsi = random.choices(self.wsi_list, weights=self.wsi_weight)[0]\n",
    "\n",
    "        img = self.single_transform(wsi)\n",
    "        \n",
    "        return img\n",
    "               \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode=='create':\n",
    "            img1 = self.sample()\n",
    "\n",
    "            augment = np.random.binomial(1,0.5)\n",
    "\n",
    "            img2 = self.augment(img1) if augment else self.sample()\n",
    "        else:\n",
    "            pkl = open(self.img_file_list[index], \"rb\")\n",
    "            img1, img2, augment = pickle.load(pkl)\n",
    "            pkl.close()\n",
    "        \n",
    "        return [img1, img2, augment]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.mode=='create':\n",
    "            acc = 0\n",
    "            for wsi in self.wsi_list:\n",
    "                h,w = wsi.size\n",
    "                acc += 1.*h*w/(224*224)\n",
    "            return int(acc)\n",
    "        \n",
    "        return len(self.img_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "familiar-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    img_file_list = glob.glob(\"/home/karman/DDP/TCGA_expt/TCGA_dataset/*/*.png\")\n",
    "    dataset = SiamDataset(img_file_list, mode='create')\n",
    "\n",
    "    out_file_path = \"/home/karman/DDP/BrC_GraphMIL/data/tcga_\"\n",
    "    if not os.path.exists(out_file_path):\n",
    "        os.makedirs(out_file_path)\n",
    "\n",
    "    torch.manual_seed(77077)\n",
    "    random.seed(71017)\n",
    "\n",
    "    idx=0\n",
    "    for data in dataset:\n",
    "        pickle_out = open(out_file_path+str(idx),\"wb\")\n",
    "        pickle.dump(data, pickle_out)\n",
    "        pickle_out.close()\n",
    "        idx += 1\n",
    "        if idx>=len(dataset):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "undefined-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    # label == 1 means same sample, label == 0 means different samples\n",
    "    def __init__(self, margin=0., do_average=True):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.eps = 1e-6\n",
    "        self.relu = nn.ReLU()\n",
    "        self.do_average = do_average\n",
    "    \n",
    "    def forward(self, out1, out2, labels):\n",
    "        dist = (out1 - out2).pow(2).sum(1)\n",
    "        loss = 0.5*(labels*dist + \n",
    "                   (1 + -1.*labels)*self.relu(self.margin - (dist+self.eps).sqrt()).pow(2))\n",
    "        return loss.mean() if self.do_average else loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "robust-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, loss_fn, train_loader, optimizer, num_epochs):\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs): \n",
    "        epoch_loss = 0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            x1 = data[0].to(device)\n",
    "            x2 = data[1].to(device)\n",
    "            label = data[2].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            out1, out2 = model(x1, x2)\n",
    "\n",
    "            loss = loss_fn(out1, out2, label) # calculates the loss\n",
    "            curr_loss = loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += curr_loss\n",
    "            \n",
    "            if batch_idx % args['log_interval'] == 0 :\n",
    "                print('Train Epoch: {} [({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, 100. * (batch_idx+1) / len(train_loader), curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "confirmed-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['batch_size'] = 150\n",
    "args['epochs'] = 3\n",
    "args['seed']=990077\n",
    "args['lr']=0.01\n",
    "args['train_ratio']=0.8\n",
    "args['log_interval']=2\n",
    "\n",
    "torch.manual_seed(args['seed'])\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thrown-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamNetwork = SiameseNetwork(model)\n",
    "\n",
    "data_file_list = sorted(glob.glob(\"/home/karman/DDP/BrC_GraphMIL/data/*\"))\n",
    "dataset = SiamDataset(data_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pleasant-arthur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [(1%)]\tLoss: 26.739262\n",
      "Train Epoch: 0 [(2%)]\tLoss: 52.246616\n",
      "Train Epoch: 0 [(3%)]\tLoss: 20.099838\n",
      "Train Epoch: 0 [(4%)]\tLoss: 8.039325\n",
      "Train Epoch: 0 [(5%)]\tLoss: 4.965273\n",
      "Train Epoch: 0 [(6%)]\tLoss: 2.330302\n",
      "Train Epoch: 0 [(7%)]\tLoss: 1.642115\n",
      "Train Epoch: 0 [(8%)]\tLoss: 1.498599\n",
      "Train Epoch: 0 [(9%)]\tLoss: 0.831232\n",
      "Train Epoch: 0 [(10%)]\tLoss: 0.957935\n",
      "Train Epoch: 0 [(11%)]\tLoss: 0.445343\n",
      "Train Epoch: 0 [(12%)]\tLoss: 0.426345\n",
      "Train Epoch: 0 [(13%)]\tLoss: 0.336960\n",
      "Train Epoch: 0 [(14%)]\tLoss: 0.203944\n",
      "Train Epoch: 0 [(15%)]\tLoss: 0.193214\n",
      "Train Epoch: 0 [(16%)]\tLoss: 0.518966\n",
      "Train Epoch: 0 [(17%)]\tLoss: 0.172473\n",
      "Train Epoch: 0 [(18%)]\tLoss: 0.542542\n",
      "Train Epoch: 0 [(19%)]\tLoss: 0.077050\n",
      "Train Epoch: 0 [(20%)]\tLoss: 0.054165\n",
      "Train Epoch: 0 [(21%)]\tLoss: 0.194822\n",
      "Train Epoch: 0 [(22%)]\tLoss: 0.048184\n",
      "Train Epoch: 0 [(23%)]\tLoss: 0.109713\n",
      "Train Epoch: 0 [(24%)]\tLoss: 0.137195\n",
      "Train Epoch: 0 [(25%)]\tLoss: 0.168259\n",
      "Train Epoch: 0 [(26%)]\tLoss: 0.068682\n",
      "Train Epoch: 0 [(27%)]\tLoss: 0.041717\n",
      "Train Epoch: 0 [(28%)]\tLoss: 0.042872\n",
      "Train Epoch: 0 [(29%)]\tLoss: 0.227822\n",
      "Train Epoch: 0 [(30%)]\tLoss: 0.092643\n",
      "Train Epoch: 0 [(31%)]\tLoss: 0.085554\n",
      "Train Epoch: 0 [(32%)]\tLoss: 0.031344\n",
      "Train Epoch: 0 [(33%)]\tLoss: 0.137034\n",
      "Train Epoch: 0 [(34%)]\tLoss: 0.040405\n",
      "Train Epoch: 0 [(35%)]\tLoss: 0.053339\n",
      "Train Epoch: 0 [(36%)]\tLoss: 0.029436\n",
      "Train Epoch: 0 [(37%)]\tLoss: 0.015078\n",
      "Train Epoch: 0 [(38%)]\tLoss: 0.081430\n",
      "Train Epoch: 0 [(39%)]\tLoss: 0.054603\n",
      "Train Epoch: 0 [(40%)]\tLoss: 0.014281\n",
      "Train Epoch: 0 [(41%)]\tLoss: 0.048754\n",
      "Train Epoch: 0 [(42%)]\tLoss: 0.076977\n",
      "Train Epoch: 0 [(43%)]\tLoss: 0.048345\n",
      "Train Epoch: 0 [(44%)]\tLoss: 0.005073\n",
      "Train Epoch: 0 [(45%)]\tLoss: 0.041320\n",
      "Train Epoch: 0 [(46%)]\tLoss: 0.040930\n",
      "Train Epoch: 0 [(47%)]\tLoss: 0.023772\n",
      "Train Epoch: 0 [(48%)]\tLoss: 0.029971\n",
      "Train Epoch: 0 [(49%)]\tLoss: 0.021845\n",
      "Train Epoch: 0 [(51%)]\tLoss: 0.024818\n",
      "Train Epoch: 0 [(52%)]\tLoss: 0.008486\n",
      "Train Epoch: 0 [(53%)]\tLoss: 0.009188\n",
      "Train Epoch: 0 [(54%)]\tLoss: 0.003042\n",
      "Train Epoch: 0 [(55%)]\tLoss: 0.022832\n",
      "Train Epoch: 0 [(56%)]\tLoss: 0.007161\n",
      "Train Epoch: 0 [(57%)]\tLoss: 0.088674\n",
      "Train Epoch: 0 [(58%)]\tLoss: 0.031098\n",
      "Train Epoch: 0 [(59%)]\tLoss: 0.008834\n",
      "Train Epoch: 0 [(60%)]\tLoss: 0.023877\n",
      "Train Epoch: 0 [(61%)]\tLoss: 0.007001\n",
      "Train Epoch: 0 [(62%)]\tLoss: 0.003537\n",
      "Train Epoch: 0 [(63%)]\tLoss: 0.066277\n",
      "Train Epoch: 0 [(64%)]\tLoss: 0.006746\n",
      "Train Epoch: 0 [(65%)]\tLoss: 0.002939\n",
      "Train Epoch: 0 [(66%)]\tLoss: 0.011595\n",
      "Train Epoch: 0 [(67%)]\tLoss: 0.009230\n",
      "Train Epoch: 0 [(68%)]\tLoss: 0.016090\n",
      "Train Epoch: 0 [(69%)]\tLoss: 0.009624\n",
      "Train Epoch: 0 [(70%)]\tLoss: 0.024704\n",
      "Train Epoch: 0 [(71%)]\tLoss: 0.014165\n",
      "Train Epoch: 0 [(72%)]\tLoss: 0.013181\n",
      "Train Epoch: 0 [(73%)]\tLoss: 0.007458\n",
      "Train Epoch: 0 [(74%)]\tLoss: 0.014811\n",
      "Train Epoch: 0 [(75%)]\tLoss: 0.007413\n",
      "Train Epoch: 0 [(76%)]\tLoss: 0.010000\n",
      "Train Epoch: 0 [(77%)]\tLoss: 0.014913\n",
      "Train Epoch: 0 [(78%)]\tLoss: 0.014457\n",
      "Train Epoch: 0 [(79%)]\tLoss: 0.003249\n",
      "Train Epoch: 0 [(80%)]\tLoss: 0.010997\n",
      "Train Epoch: 0 [(81%)]\tLoss: 0.006719\n",
      "Train Epoch: 0 [(82%)]\tLoss: 0.002655\n",
      "Train Epoch: 0 [(83%)]\tLoss: 0.004721\n",
      "Train Epoch: 0 [(84%)]\tLoss: 0.016416\n",
      "Train Epoch: 0 [(85%)]\tLoss: 0.026894\n",
      "Train Epoch: 0 [(86%)]\tLoss: 0.007708\n",
      "Train Epoch: 0 [(87%)]\tLoss: 0.010740\n",
      "Train Epoch: 0 [(88%)]\tLoss: 0.049635\n",
      "Train Epoch: 0 [(89%)]\tLoss: 0.020274\n",
      "Train Epoch: 0 [(90%)]\tLoss: 0.012753\n",
      "Train Epoch: 0 [(91%)]\tLoss: 0.013885\n",
      "Train Epoch: 0 [(92%)]\tLoss: 0.009532\n",
      "Train Epoch: 0 [(93%)]\tLoss: 0.008053\n",
      "Train Epoch: 0 [(94%)]\tLoss: 0.002530\n",
      "Train Epoch: 0 [(95%)]\tLoss: 0.001663\n",
      "Train Epoch: 0 [(96%)]\tLoss: 0.017347\n",
      "Train Epoch: 0 [(97%)]\tLoss: 0.001204\n",
      "Train Epoch: 0 [(98%)]\tLoss: 0.005195\n",
      "Train Epoch: 0 [(99%)]\tLoss: 0.007036\n",
      "Train Epoch: 1 [(1%)]\tLoss: 0.008539\n",
      "Train Epoch: 1 [(2%)]\tLoss: 0.003358\n",
      "Train Epoch: 1 [(3%)]\tLoss: 0.022499\n",
      "Train Epoch: 1 [(4%)]\tLoss: 0.008916\n",
      "Train Epoch: 1 [(5%)]\tLoss: 0.006068\n",
      "Train Epoch: 1 [(6%)]\tLoss: 0.020172\n",
      "Train Epoch: 1 [(7%)]\tLoss: 0.008983\n",
      "Train Epoch: 1 [(8%)]\tLoss: 0.049299\n",
      "Train Epoch: 1 [(9%)]\tLoss: 0.010978\n",
      "Train Epoch: 1 [(10%)]\tLoss: 0.003342\n",
      "Train Epoch: 1 [(11%)]\tLoss: 0.012651\n",
      "Train Epoch: 1 [(12%)]\tLoss: 0.023267\n",
      "Train Epoch: 1 [(13%)]\tLoss: 0.012071\n",
      "Train Epoch: 1 [(14%)]\tLoss: 0.004645\n",
      "Train Epoch: 1 [(15%)]\tLoss: 0.008249\n",
      "Train Epoch: 1 [(16%)]\tLoss: 0.012321\n",
      "Train Epoch: 1 [(17%)]\tLoss: 0.017701\n",
      "Train Epoch: 1 [(18%)]\tLoss: 0.006359\n",
      "Train Epoch: 1 [(19%)]\tLoss: 0.007505\n",
      "Train Epoch: 1 [(20%)]\tLoss: 0.014582\n",
      "Train Epoch: 1 [(21%)]\tLoss: 0.019762\n",
      "Train Epoch: 1 [(22%)]\tLoss: 0.008033\n",
      "Train Epoch: 1 [(23%)]\tLoss: 0.008385\n",
      "Train Epoch: 1 [(24%)]\tLoss: 0.010895\n",
      "Train Epoch: 1 [(25%)]\tLoss: 0.015311\n",
      "Train Epoch: 1 [(26%)]\tLoss: 0.008275\n",
      "Train Epoch: 1 [(27%)]\tLoss: 0.003629\n",
      "Train Epoch: 1 [(28%)]\tLoss: 0.023158\n",
      "Train Epoch: 1 [(29%)]\tLoss: 0.013442\n",
      "Train Epoch: 1 [(30%)]\tLoss: 0.006565\n",
      "Train Epoch: 1 [(31%)]\tLoss: 0.004164\n",
      "Train Epoch: 1 [(32%)]\tLoss: 0.055783\n",
      "Train Epoch: 1 [(33%)]\tLoss: 0.005906\n",
      "Train Epoch: 1 [(34%)]\tLoss: 0.003406\n",
      "Train Epoch: 1 [(35%)]\tLoss: 0.001035\n",
      "Train Epoch: 1 [(36%)]\tLoss: 0.005953\n",
      "Train Epoch: 1 [(37%)]\tLoss: 0.003482\n",
      "Train Epoch: 1 [(38%)]\tLoss: 0.004763\n",
      "Train Epoch: 1 [(39%)]\tLoss: 0.010298\n",
      "Train Epoch: 1 [(40%)]\tLoss: 0.001353\n",
      "Train Epoch: 1 [(41%)]\tLoss: 0.004452\n",
      "Train Epoch: 1 [(42%)]\tLoss: 0.004814\n",
      "Train Epoch: 1 [(43%)]\tLoss: 0.004013\n",
      "Train Epoch: 1 [(44%)]\tLoss: 0.002314\n",
      "Train Epoch: 1 [(45%)]\tLoss: 0.002813\n",
      "Train Epoch: 1 [(46%)]\tLoss: 0.005610\n",
      "Train Epoch: 1 [(47%)]\tLoss: 0.002742\n",
      "Train Epoch: 1 [(48%)]\tLoss: 0.011394\n",
      "Train Epoch: 1 [(49%)]\tLoss: 0.001716\n",
      "Train Epoch: 1 [(51%)]\tLoss: 0.003351\n",
      "Train Epoch: 1 [(52%)]\tLoss: 0.001845\n",
      "Train Epoch: 1 [(53%)]\tLoss: 0.001543\n",
      "Train Epoch: 1 [(54%)]\tLoss: 0.002408\n",
      "Train Epoch: 1 [(55%)]\tLoss: 0.002378\n",
      "Train Epoch: 1 [(56%)]\tLoss: 0.002579\n",
      "Train Epoch: 1 [(57%)]\tLoss: 0.002190\n",
      "Train Epoch: 1 [(58%)]\tLoss: 0.003078\n",
      "Train Epoch: 1 [(59%)]\tLoss: 0.001111\n",
      "Train Epoch: 1 [(60%)]\tLoss: 0.004649\n",
      "Train Epoch: 1 [(61%)]\tLoss: 0.003193\n",
      "Train Epoch: 1 [(62%)]\tLoss: 0.001570\n",
      "Train Epoch: 1 [(63%)]\tLoss: 0.002014\n",
      "Train Epoch: 1 [(64%)]\tLoss: 0.002496\n",
      "Train Epoch: 1 [(65%)]\tLoss: 0.001835\n",
      "Train Epoch: 1 [(66%)]\tLoss: 0.003728\n",
      "Train Epoch: 1 [(67%)]\tLoss: 0.000351\n",
      "Train Epoch: 1 [(68%)]\tLoss: 0.001494\n",
      "Train Epoch: 1 [(69%)]\tLoss: 0.001146\n",
      "Train Epoch: 1 [(70%)]\tLoss: 0.001138\n",
      "Train Epoch: 1 [(71%)]\tLoss: 0.001566\n",
      "Train Epoch: 1 [(72%)]\tLoss: 0.001171\n",
      "Train Epoch: 1 [(73%)]\tLoss: 0.001170\n",
      "Train Epoch: 1 [(74%)]\tLoss: 0.000491\n",
      "Train Epoch: 1 [(75%)]\tLoss: 0.000437\n",
      "Train Epoch: 1 [(76%)]\tLoss: 0.001561\n",
      "Train Epoch: 1 [(77%)]\tLoss: 0.002054\n",
      "Train Epoch: 1 [(78%)]\tLoss: 0.000465\n",
      "Train Epoch: 1 [(79%)]\tLoss: 0.001325\n",
      "Train Epoch: 1 [(80%)]\tLoss: 0.002340\n",
      "Train Epoch: 1 [(81%)]\tLoss: 0.001172\n",
      "Train Epoch: 1 [(82%)]\tLoss: 0.001575\n",
      "Train Epoch: 1 [(83%)]\tLoss: 0.001117\n",
      "Train Epoch: 1 [(84%)]\tLoss: 0.001049\n",
      "Train Epoch: 1 [(85%)]\tLoss: 0.001293\n",
      "Train Epoch: 1 [(86%)]\tLoss: 0.001118\n",
      "Train Epoch: 1 [(87%)]\tLoss: 0.002016\n",
      "Train Epoch: 1 [(88%)]\tLoss: 0.000724\n",
      "Train Epoch: 1 [(89%)]\tLoss: 0.000867\n",
      "Train Epoch: 1 [(90%)]\tLoss: 0.001065\n",
      "Train Epoch: 1 [(91%)]\tLoss: 0.001371\n",
      "Train Epoch: 1 [(92%)]\tLoss: 0.000491\n",
      "Train Epoch: 1 [(93%)]\tLoss: 0.000445\n",
      "Train Epoch: 1 [(94%)]\tLoss: 0.001216\n",
      "Train Epoch: 1 [(95%)]\tLoss: 0.000611\n",
      "Train Epoch: 1 [(96%)]\tLoss: 0.000802\n",
      "Train Epoch: 1 [(97%)]\tLoss: 0.000634\n",
      "Train Epoch: 1 [(98%)]\tLoss: 0.000452\n",
      "Train Epoch: 1 [(99%)]\tLoss: 0.000648\n",
      "Train Epoch: 2 [(1%)]\tLoss: 0.000732\n",
      "Train Epoch: 2 [(2%)]\tLoss: 0.001479\n",
      "Train Epoch: 2 [(3%)]\tLoss: 0.000698\n",
      "Train Epoch: 2 [(4%)]\tLoss: 0.000372\n",
      "Train Epoch: 2 [(5%)]\tLoss: 0.000265\n",
      "Train Epoch: 2 [(6%)]\tLoss: 0.000801\n",
      "Train Epoch: 2 [(7%)]\tLoss: 0.002762\n",
      "Train Epoch: 2 [(8%)]\tLoss: 0.001195\n",
      "Train Epoch: 2 [(9%)]\tLoss: 0.000544\n",
      "Train Epoch: 2 [(10%)]\tLoss: 0.000498\n",
      "Train Epoch: 2 [(11%)]\tLoss: 0.000620\n",
      "Train Epoch: 2 [(12%)]\tLoss: 0.000479\n",
      "Train Epoch: 2 [(13%)]\tLoss: 0.000484\n",
      "Train Epoch: 2 [(14%)]\tLoss: 0.000784\n",
      "Train Epoch: 2 [(15%)]\tLoss: 0.001309\n",
      "Train Epoch: 2 [(16%)]\tLoss: 0.000445\n",
      "Train Epoch: 2 [(17%)]\tLoss: 0.000760\n",
      "Train Epoch: 2 [(18%)]\tLoss: 0.000287\n",
      "Train Epoch: 2 [(19%)]\tLoss: 0.000638\n",
      "Train Epoch: 2 [(20%)]\tLoss: 0.000907\n",
      "Train Epoch: 2 [(21%)]\tLoss: 0.000064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [(22%)]\tLoss: 0.000286\n",
      "Train Epoch: 2 [(23%)]\tLoss: 0.000114\n",
      "Train Epoch: 2 [(24%)]\tLoss: 0.001462\n",
      "Train Epoch: 2 [(25%)]\tLoss: 0.000905\n",
      "Train Epoch: 2 [(26%)]\tLoss: 0.000779\n",
      "Train Epoch: 2 [(27%)]\tLoss: 0.000914\n",
      "Train Epoch: 2 [(28%)]\tLoss: 0.000771\n",
      "Train Epoch: 2 [(29%)]\tLoss: 0.000618\n",
      "Train Epoch: 2 [(30%)]\tLoss: 0.001345\n",
      "Train Epoch: 2 [(31%)]\tLoss: 0.000705\n",
      "Train Epoch: 2 [(32%)]\tLoss: 0.001530\n",
      "Train Epoch: 2 [(33%)]\tLoss: 0.000218\n",
      "Train Epoch: 2 [(34%)]\tLoss: 0.000634\n",
      "Train Epoch: 2 [(35%)]\tLoss: 0.000491\n",
      "Train Epoch: 2 [(36%)]\tLoss: 0.000661\n",
      "Train Epoch: 2 [(37%)]\tLoss: 0.000659\n",
      "Train Epoch: 2 [(38%)]\tLoss: 0.000807\n",
      "Train Epoch: 2 [(39%)]\tLoss: 0.002763\n",
      "Train Epoch: 2 [(40%)]\tLoss: 0.000372\n",
      "Train Epoch: 2 [(41%)]\tLoss: 0.000299\n",
      "Train Epoch: 2 [(42%)]\tLoss: 0.000422\n",
      "Train Epoch: 2 [(43%)]\tLoss: 0.000506\n",
      "Train Epoch: 2 [(44%)]\tLoss: 0.001325\n",
      "Train Epoch: 2 [(45%)]\tLoss: 0.000551\n",
      "Train Epoch: 2 [(46%)]\tLoss: 0.000124\n",
      "Train Epoch: 2 [(47%)]\tLoss: 0.000492\n",
      "Train Epoch: 2 [(48%)]\tLoss: 0.001198\n",
      "Train Epoch: 2 [(49%)]\tLoss: 0.000325\n",
      "Train Epoch: 2 [(51%)]\tLoss: 0.001324\n",
      "Train Epoch: 2 [(52%)]\tLoss: 0.000061\n",
      "Train Epoch: 2 [(53%)]\tLoss: 0.000735\n",
      "Train Epoch: 2 [(54%)]\tLoss: 0.000700\n",
      "Train Epoch: 2 [(55%)]\tLoss: 0.000181\n",
      "Train Epoch: 2 [(56%)]\tLoss: 0.000319\n",
      "Train Epoch: 2 [(57%)]\tLoss: 0.000777\n",
      "Train Epoch: 2 [(58%)]\tLoss: 0.000402\n",
      "Train Epoch: 2 [(59%)]\tLoss: 0.000263\n",
      "Train Epoch: 2 [(60%)]\tLoss: 0.000608\n",
      "Train Epoch: 2 [(61%)]\tLoss: 0.000147\n",
      "Train Epoch: 2 [(62%)]\tLoss: 0.000704\n",
      "Train Epoch: 2 [(63%)]\tLoss: 0.001000\n",
      "Train Epoch: 2 [(64%)]\tLoss: 0.000488\n",
      "Train Epoch: 2 [(65%)]\tLoss: 0.000409\n",
      "Train Epoch: 2 [(66%)]\tLoss: 0.000549\n",
      "Train Epoch: 2 [(67%)]\tLoss: 0.000075\n",
      "Train Epoch: 2 [(68%)]\tLoss: 0.000846\n",
      "Train Epoch: 2 [(69%)]\tLoss: 0.000297\n",
      "Train Epoch: 2 [(70%)]\tLoss: 0.000375\n",
      "Train Epoch: 2 [(71%)]\tLoss: 0.000532\n",
      "Train Epoch: 2 [(72%)]\tLoss: 0.000167\n",
      "Train Epoch: 2 [(73%)]\tLoss: 0.000097\n",
      "Train Epoch: 2 [(74%)]\tLoss: 0.000436\n",
      "Train Epoch: 2 [(75%)]\tLoss: 0.000144\n",
      "Train Epoch: 2 [(76%)]\tLoss: 0.000642\n",
      "Train Epoch: 2 [(77%)]\tLoss: 0.000318\n",
      "Train Epoch: 2 [(78%)]\tLoss: 0.000187\n",
      "Train Epoch: 2 [(79%)]\tLoss: 0.000160\n",
      "Train Epoch: 2 [(80%)]\tLoss: 0.000481\n",
      "Train Epoch: 2 [(81%)]\tLoss: 0.000557\n",
      "Train Epoch: 2 [(82%)]\tLoss: 0.000709\n",
      "Train Epoch: 2 [(83%)]\tLoss: 0.000189\n",
      "Train Epoch: 2 [(84%)]\tLoss: 0.000250\n",
      "Train Epoch: 2 [(85%)]\tLoss: 0.000108\n",
      "Train Epoch: 2 [(86%)]\tLoss: 0.000230\n",
      "Train Epoch: 2 [(87%)]\tLoss: 0.001721\n",
      "Train Epoch: 2 [(88%)]\tLoss: 0.001022\n",
      "Train Epoch: 2 [(89%)]\tLoss: 0.000824\n",
      "Train Epoch: 2 [(90%)]\tLoss: 0.000302\n",
      "Train Epoch: 2 [(91%)]\tLoss: 0.000173\n",
      "Train Epoch: 2 [(92%)]\tLoss: 0.000112\n",
      "Train Epoch: 2 [(93%)]\tLoss: 0.000116\n",
      "Train Epoch: 2 [(94%)]\tLoss: 0.000168\n",
      "Train Epoch: 2 [(95%)]\tLoss: 0.000747\n",
      "Train Epoch: 2 [(96%)]\tLoss: 0.000808\n",
      "Train Epoch: 2 [(97%)]\tLoss: 0.000154\n",
      "Train Epoch: 2 [(98%)]\tLoss: 0.000337\n",
      "Train Epoch: 2 [(99%)]\tLoss: 0.000209\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=dataset, batch_size=args['batch_size'], shuffle = True, **kwargs)\n",
    "\n",
    "loss_fn = ContrastiveLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "\n",
    "train(args, siamNetwork, device, loss_fn, train_loader, optimizer, args['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': args['epoch'],\n",
    "    'model_state_dict': siamNetwork.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, 'siamese_3epoch_1wsi_new.pth.tar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo37]",
   "language": "python",
   "name": "conda-env-geo37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
