{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os, sys, glob, pickle\n",
    "from xml.dom import minidom\n",
    "import matplotlib.path as mplPath\n",
    "import numpy as np\n",
    "#import openslide\n",
    "import time\n",
    "import pdb\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'tenpercent_resnet18.ckpt'\n",
    "RETURN_PREACTIVATION = True  # return features from the model, if false return classification logits\n",
    "NUM_CLASSES = 4  # only used if RETURN_PREACTIVATION = False\n",
    "\n",
    "\n",
    "def load_model_weights(model, weights):\n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "    weights = {k: v for k, v in weights.items() if k in model_dict}\n",
    "    if weights == {}:\n",
    "        print('No weight could be loaded..')\n",
    "    model_dict.update(weights)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = models.__dict__['resnet18'](pretrained=False)\n",
    "\n",
    "state = torch.load(MODEL_PATH, map_location=device)\n",
    "\n",
    "state_dict = state['state_dict']\n",
    "for key in list(state_dict.keys()):\n",
    "    state_dict[key.replace('model.', '').replace('resnet.', '')] = state_dict.pop(key)\n",
    "\n",
    "model = load_model_weights(model, state_dict)\n",
    "\n",
    "if RETURN_PREACTIVATION:\n",
    "    model.fc = torch.nn.Sequential()\n",
    "else:\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward_once(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_once(x1)\n",
    "        out2 = self.forward_once(x2)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamDataset(Dataset):\n",
    "    def __init__(self, img_file_list, mode='load', affine_param=5, jitter_param=0.4):\n",
    "        self.img_file_list = img_file_list\n",
    "        \n",
    "        self.mode = mode\n",
    "        if mode=='create':\n",
    "            self.single_transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.RandomCrop(224),\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ])\n",
    "            self.augment = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.ToPILImage(),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "                torchvision.transforms.RandomAffine(affine_param),\n",
    "                torchvision.transforms.ColorJitter(\n",
    "                    brightness=jitter_param,\n",
    "                    contrast=jitter_param,\n",
    "                    saturation=jitter_param),\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "            self.wsi_list = []\n",
    "            self.wsi_weight = []\n",
    "            for img_file in img_file_list:\n",
    "                wsi = Image.open(img_file).convert('RGB')\n",
    "                self.wsi_list.append(wsi)\n",
    "                h,w = wsi.size\n",
    "                self.wsi_weight.append(h*w)\n",
    "        \n",
    "    def sample(self):\n",
    "        wsi = random.choices(self.wsi_list, weights=self.wsi_weight)[0]\n",
    "\n",
    "        img = self.single_transform(wsi)\n",
    "        \n",
    "        return img\n",
    "               \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode=='create':\n",
    "            img1 = self.sample()\n",
    "\n",
    "            augment = np.random.binomial(1,0.5)\n",
    "\n",
    "            img2 = self.augment(img1) if augment else self.sample()\n",
    "        else:\n",
    "            pkl = open(self.img_file_list[index], \"rb\")\n",
    "            img1, img2, augment = pickle.load(pkl)\n",
    "            pkl.close()\n",
    "        \n",
    "        return [img1, img2, augment]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.mode=='create':\n",
    "            acc = 0\n",
    "            for wsi in self.wsi_list:\n",
    "                h,w = wsi.size\n",
    "                acc += 1.*h*w/(224*224)\n",
    "            return int(acc)\n",
    "        \n",
    "        return len(self.img_file_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py37] *",
   "language": "python",
   "name": "conda-env-.conda-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
